---
title: "전 회사에서 선택했던 데이터 분석 환경"
description: "MinIO + DuckDB + Python + Polars"
pubDate: "Oct 10 2025"
badge: "분석 관련"
color: "bg-red-100 text-red-800"
tags: ["MinIO", "DuckDB", "Polars", "DB"]
---

기존에는 MySQL 기반으로 데이터 분석 환경을 운영하고 있었다. 하지만 분석 쿼리가 복잡해질수록 응답 속도가 느려졌고, 데이터가 누적될수록 스토리지 비용 부담도 커졌다. 특히 대용량 조인이나 집계 연산에서 성능 저하가 두드러졌다. 새로운 환경을 설계하기 위해 먼저 우리가 다루는 데이터의 실제 규모부터 파악해야 했다.

우리는 새로운 분석 환경을 구축하면서 최소한의 인프라로 최대한 빠르게 처리하는 것을 목표로 삼았다. 이를 위해 우리가 분석할 데이터의 규모를 인지할 필요가 있다. 게임 회사에서 데이터 분석을 진행하면서 느낀 것은, 생각보다 거대한 데이터를 다루지는 않는다는 것이다. (실제 데이터 스토리지의 크기가 종종 과장되어 있다는 의견에 대해서는 [이 글](https://motherduck.com/blog/big-data-is-dead/)을 참고하는게 좋다.) 스파크와 같은 대형 데이터 분산 처리 시스템을 사용하는 것은 닭 잡는데 소 잡는 도구를 사용하는 꼴이 되는 경우가 많았다는 것이었다. 내가 다뤘던 게임이 매년 1조원 이상의 매출을 올리는 거대한 게임이었더라도, 분석 데이터의 규모가 어마어마하게 크진 않았었다.

우리는 비용 문제로 인해 GCP나 AWS같은 완전 관리형 클라우드 데이터 웨어하우스를 사용할 수 없는 상황이었다. BigQuery나 Snowflake 같은 솔루션은 기술적으로 강력하지만, 현실적으로 경제적인 이유 때문에 이런 시스템을 구성하자고 조직을 설득하기 쉽지 않았다. 당장 가시적인 투자 비용이 발생하는 데 비해, 분석 환경 개선으로 인한 효과는 정량적으로 증명하기 어려웠기 때문이다. Spark 클러스터를 구축하는 방안도 검토했지만, 우리 데이터 규모에서는 과도한 인프라였다.

결국 자체 서버를 이용하며 분석에 적합한 데이터 레이크를 구축하는 방향으로 결정했다. 오픈소스 기반으로 비용을 최소화하면서도, 분석 성능은 기존보다 향상시킬 수 있는 조합을 찾아야 했다.

#### MinIO: 데이터 스토리지

데이터 스토리지는 MinIO를 선택하였다. 자체 서버에서 운영할 수 있고, 오픈 소스이기 때문에 비용 부담이 전혀 없었다. S3 호환 API를 제공하여 추후 클라우드로 마이그레이션할 때도 코드 변경이 최소화된다는 점도 매력적이었다. 무엇보다 압축 효율이 뛰어나고 분석 속도가 빠르며 데이터 스키마 설정에 큰 노력이 필요 없는 Parquet 파일 포맷을 사용하기 위함이기도 했다.

#### DuckDB: 분석 엔진

분석 엔진으로는 DuckDB를 사용하였다. 별도의 서버 프로세스를 포함하지 않아 Python 라이브러리로 임포트해서 쓰기 편하고, MinIO 내부의 Parquet 처리를 지원해 이를 직접 쿼리할 수 있었다. 또한 DuckDB는 단일 노드에서 최적화하여 쿼리를 처리하기 때문에 속도 측면에서 분석 쿼리의 성능이 뛰어나다. MySQL에서 수십 초 걸리던 집계 쿼리가 DuckDB에서는 수 초 내로 완료되는 경우가 많았다.

#### Polars: 데이터 처리

Polars는 Pandas와 달리 쿼리 최적화와 병렬 처리를 기본으로 하기 때문에 빠른 속도로 데이터를 처리할 수 있다. 또한, 로컬 환경에서 데이터를 분석하다 보면 메모리 이슈가 일어나기 쉬운데, Polars는 전체 데이터 처리 파이프라인을 최적화하는 Lazy Evaluation을 진행할 수 있어 해당 이슈를 어느 정도 해소할 수 있다.



이 기술 스택으로 인해 기존 MySQL 기반 분석 환경보다 빠르고 압축 효율이 좋은 데이터 분석 환경을 구축할 수 있었다. 쿼리 응답 속도는 크게 개선되었고, 동일한 데이터를 저장하는 데 필요한 스토리지 용량도 감소했다. 서문에 작성한 것처럼 Spark를 이용하여 데이터 분석 환경을 구축하는 것은 우리가 다루는 데이터 크기에서는 너무나 과도했다. 

물론 잠재적인 리스크도 있다. 첫째로, 완전 관리형 클라우드 데이터 웨어하우스와 달리 실시간 스트리밍 데이터를 처리하기 어렵다는 단점이 있다. 따라서 실시간으로 데이터를 모니터링하거나 짧은 시간 이전에 생긴 이슈에 신속하게 대응하기 위해서는 추가적인 파이프라인이 필요하다. 둘째로, 데이터 품질 관리가 어렵다는 점이 있다. 여러 개의 Parquet을 관리하기 때문에 만약 중간에 컬럼이 누락되었다거나 잘못된 데이터가 입력되었다거나 하는 문제가 있을 경우 이를 사전에 막아내거나 빠르게 파악하기 어렵다는 단점이 있다. 마지막으로 아직 해당 데이터 환경의 생태계와 커뮤니티의 규모가 작기 때문에 다른 도구들과의 호환성이 비교적 낮고 학습하기 어렵다는 단점이 있다. 특히 고급 데이터 분석을 해야 할 때 기존의 전통적인 방법을 혼용해야 하는 경우가 허다하다.

그렇지만 이러한 리스크를 인지하고 있다면 충분히 이를 해결할 수 있는 방법을 찾아낼 수 있을 것이다. 우리의 경우 비용 절감과 쿼리 성능 개선이라는 핵심 목표를 달성했고, 이는 리스크를 감수할 만한 가치가 있는 선택이었다.

